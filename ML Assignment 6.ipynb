{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57e7c675",
   "metadata": {},
   "source": [
    "# Practice Lab: Decision Trees\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1 - Packages\n",
    "First, let's run the cell below to import all the packages that you will need during this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ad4939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from public_tests import *\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ae87d9",
   "metadata": {},
   "source": [
    "## 2 - Dataset\n",
    "we have 10 examples of mushrooms. For each example, we have\n",
    "Three features\n",
    "Cap Color (Brown or Red),\n",
    " Stalk Shape (Tapering (as in \\/) or Enlarging (as in /\\)), and\n",
    "Solitary (Yes or No)\n",
    "\n",
    "Label\n",
    "Edible (1 indicating yes or 0 indicating poisonous)\n",
    "\n",
    "\n",
    "## One hot encoded dataset\n",
    "For ease of implementation, we have one-hot encoded the features (turned them into 0 or 1 valued features)\n",
    "therefore,\n",
    "\n",
    "X_train contains three features for each example\n",
    "\n",
    "Brown Color (A value of 1 indicates \"Brown\" cap color and 0 indicates \"Red\" cap color)\n",
    "\n",
    "Tapering Shape (A value of 1 indicates \"Tapering Stalk Shape\" and 0 indicates \"Enlarging\" stalk shape)\n",
    "\n",
    "Solitary (A value of 1 indicates \"Yes\" and 0 indicates \"No\")\n",
    "\n",
    "y_train is whether the mushroom is edible\n",
    "\n",
    "y = 1 indicates edible\n",
    "\n",
    "y = 0 indicates poisonous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6e2424",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([[1,1,1],[1,0,1],[1,0,0],[1,0,0],[1,1,1],[0,1,1],[0,0,0],[1,0,1],[0,1,0],[1,0,0]])\n",
    "y_train = np.array([1,1,0,0,1,0,0,1,1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "951018f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few elements of X_train:\n",
      " [[1 1 1]\n",
      " [1 0 1]\n",
      " [1 0 0]\n",
      " [1 0 0]\n",
      " [1 1 1]]\n",
      "Type of X_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First few elements of X_train:\\n\", X_train[:5])\n",
    "print(\"Type of X_train:\",type(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a33ba740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few elements of y_train: [1 1 0 0 1]\n",
      "Type of y_train: <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(\"First few elements of y_train:\", y_train[:5])\n",
    "print(\"Type of y_train:\",type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bc16892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X_train is: (10, 3)\n",
      "The shape of y_train is:  (10,)\n",
      "Number of training examples (m): 10\n"
     ]
    }
   ],
   "source": [
    "print ('The shape of X_train is:', X_train.shape)\n",
    "print ('The shape of y_train is: ', y_train.shape)\n",
    "print ('Number of training examples (m):', len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e78798d",
   "metadata": {},
   "source": [
    "# 4 - Decision Tree Refresher \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Calculate entropy\n",
    "\n",
    "\n",
    "## Exercise 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "98c85b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C1\n",
    "# GRADED FUNCTION: compute_entropy\n",
    "def compute_entropy(y):\n",
    "\n",
    " \n",
    " entropy = 0.\n",
    "\n",
    " if len(y) != 0:\n",
    "   \n",
    "     p1 = len(y[y == 1]) / len(y)\n",
    "   \n",
    "     if p1 != 0 and p1 != 1:\n",
    "        \n",
    "         entropy = -p1 * np.log2(p1) - (1 - p1) * np.log2(1 - p1)\n",
    "     else:\n",
    "         entropy = 0.        \n",
    "\n",
    " return entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b392a",
   "metadata": {},
   "source": [
    " You can check if your implementation was correct by running the following test code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4498c451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy at root node:  1.0\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Entropy at root node: \", compute_entropy(y_train)) \n",
    "\n",
    "# UNIT TESTS\n",
    "compute_entropy_test(compute_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234256c4",
   "metadata": {},
   "source": [
    "## Split dataset\n",
    "\n",
    "\n",
    "\n",
    "## Exercise 2\n",
    "For each index in node_indices\n",
    "\n",
    "If the value of X at that index for that feature is 1, add the index to left_indices\n",
    "\n",
    "If the value of X at that index for that feature is 0, add the index to right_indices\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aed1c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C2\n",
    "# GRADED FUNCTION: split_dataset\n",
    "def split_dataset(X, node_indices, feature):\n",
    "   \n",
    "    left_indices = []\n",
    "    right_indices = []\n",
    "    \n",
    "    for i in node_indices:   \n",
    "       if X[i][feature] == 1:\n",
    "        \n",
    "           left_indices.append(i)\n",
    "       else:\n",
    "           right_indices.append(i)\n",
    "        \n",
    "    return left_indices, right_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53646159",
   "metadata": {},
   "source": [
    " Now, let's check our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0d3e87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydot in c:\\users\\madinalaptops\\anaconda3\\lib\\site-packages (1.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\users\\madinalaptops\\anaconda3\\lib\\site-packages (from pydot) (3.0.4)\n",
      "Collecting pydotplus\n",
      "  Downloading pydotplus-2.0.2.tar.gz (278 kB)\n",
      "Requirement already satisfied: pyparsing>=2.0.1 in c:\\users\\madinalaptops\\anaconda3\\lib\\site-packages (from pydotplus) (3.0.4)\n",
      "Building wheels for collected packages: pydotplus\n",
      "  Building wheel for pydotplus (setup.py): started\n",
      "  Building wheel for pydotplus (setup.py): finished with status 'done'\n",
      "  Created wheel for pydotplus: filename=pydotplus-2.0.2-py3-none-any.whl size=24575 sha256=cf6a9f415af906b3270ef678ebed17bcb90f5e0605cdfb1fce4279e9980dfab0\n",
      "  Stored in directory: c:\\users\\madinalaptops\\appdata\\local\\pip\\cache\\wheels\\89\\e5\\de\\6966007cf223872eedfbebbe0e074534e72e9128c8fd4b55eb\n",
      "Successfully built pydotplus\n",
      "Installing collected packages: pydotplus\n",
      "Successfully installed pydotplus-2.0.2\n",
      "Collecting graphviz\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "Installing collected packages: graphviz\n",
      "Successfully installed graphviz-0.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydot\n",
    "!pip install pydotplus\n",
    "!pip install graphviz\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a38f4769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left indices:  [0, 1, 2, 3, 4, 7, 9]\n",
      "Right indices:  [5, 6, 8]\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "root_indices = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "# The dataset only has three features, so this value can be 0 (Brown Cap), 1 (Tapering Stalk Shape) or 2 (Solitary)\n",
    "feature = 0\n",
    "\n",
    "left_indices, right_indices = split_dataset(X_train, root_indices, feature)\n",
    "\n",
    "print(\"Left indices: \", left_indices)\n",
    "print(\"Right indices: \", right_indices)\n",
    "\n",
    "# Visualize the split \n",
    "# generate_split_viz(root_indices, left_indices, right_indices, feature)\n",
    "\n",
    "# UNIT TESTS    \n",
    "split_dataset_test(split_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809a8325",
   "metadata": {},
   "source": [
    "## 4.3 Calculate information gain\n",
    "Next, we'll write a function called information_gain that takes in the training data, the indices at a node and a feature to split on and returns the information gain from the split.\n",
    "\n",
    "\n",
    "## Exercise 3\n",
    " compute_information_gain() function shown below to compute\n",
    "\n",
    "Information Gain=ùêª(ùëùnode1)‚àí(ùë§leftùêª(ùëùleft1)+ùë§rightùêª(ùëùright1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfd072e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C3\n",
    "# GRADED FUNCTION: compute_information_gain\n",
    "\n",
    "def compute_information_gain(X, y, node_indices, feature):\n",
    "   # Split dataset\n",
    "   left_indices, right_indices = split_dataset(X, node_indices, feature)\n",
    "\n",
    "   # Some useful variables\n",
    "   X_node, y_node = X[node_indices], y[node_indices]\n",
    "   X_left, y_left = X[left_indices], y[left_indices]\n",
    "   X_right, y_right = X[right_indices], y[right_indices]\n",
    "\n",
    "   # You need to return the following variables correctly\n",
    "   information_gain = 0\n",
    "\n",
    "   ### START CODE HERE ###\n",
    "  \n",
    "   node_entropy = compute_entropy(y_node)\n",
    "   left_entropy = compute_entropy(y_left)\n",
    "   right_entropy = compute_entropy(y_right)\n",
    "\n",
    "   w_left = len(X_left) / len(X_node)\n",
    "\n",
    "   \n",
    "   w_right = len(X_right) / len(X_node)\n",
    "\n",
    "   weighted_entropy = w_left * left_entropy + w_right * right_entropy\n",
    "\n",
    "   information_gain = node_entropy - weighted_entropy\n",
    " \n",
    "\n",
    "   return information_gain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c096199",
   "metadata": {},
   "source": [
    "we can now check our implementation using the cell below and calculate what the information gain would be from splitting on each of the featues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d17fbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information Gain from splitting the root on brown cap:  0.034851554559677034\n",
      "Information Gain from splitting the root on tapering stalk shape:  0.12451124978365313\n",
      "Information Gain from splitting the root on solitary:  0.2780719051126377\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "info_gain0 = compute_information_gain(X_train, y_train, root_indices, feature=0)\n",
    "print(\"Information Gain from splitting the root on brown cap: \", info_gain0)\n",
    "\n",
    "info_gain1 = compute_information_gain(X_train, y_train, root_indices, feature=1)\n",
    "print(\"Information Gain from splitting the root on tapering stalk shape: \", info_gain1)\n",
    "\n",
    "info_gain2 = compute_information_gain(X_train, y_train, root_indices, feature=2)\n",
    "print(\"Information Gain from splitting the root on solitary: \", info_gain2)\n",
    "\n",
    "# UNIT TESTS\n",
    "compute_information_gain_test(compute_information_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546a6ead",
   "metadata": {},
   "source": [
    "## 4.4 Get best split\n",
    "Now let's write a function to get the best feature to split on by computing the information gain from each feature as we did above and returning the feature that gives the maximum information gain\n",
    "\n",
    "\n",
    "## Exercise 4\n",
    "lets complete the get_best_split() function shown below.\n",
    "\n",
    "The function takes in the training data, along with the indices of datapoint at that node\n",
    "\n",
    "The output of the function is the feature that gives the maximum information gain\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "498f5f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNQ_C4\n",
    "# GRADED FUNCTION: get_best_split\n",
    "\n",
    "def get_best_split(X, y, node_indices):   \n",
    "\n",
    "    \n",
    "    # Some useful variables\n",
    "    num_features = X.shape[1]\n",
    "    \n",
    "    # You need to return the following variables correctly\n",
    "    best_feature = -1\n",
    "    \n",
    "    max_info_gain = 0\n",
    "\n",
    "   \n",
    "    for feature in range(num_features): \n",
    "\n",
    "      \n",
    "       info_gain = compute_information_gain(X, y, node_indices, feature)\n",
    "\n",
    "       \n",
    "       if info_gain > max_info_gain:  \n",
    "           \n",
    "           max_info_gain = info_gain\n",
    "           best_feature =  feature  \n",
    "   \n",
    "    return best_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6bd8c599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best feature to split on: 2\n",
      "\u001b[92m All tests passed.\n"
     ]
    }
   ],
   "source": [
    "best_feature = get_best_split(X_train, y_train, root_indices)\n",
    "print(\"Best feature to split on: %d\" % best_feature)\n",
    "\n",
    "# UNIT TESTS\n",
    "get_best_split_test(get_best_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2c42f",
   "metadata": {},
   "source": [
    " As we saw above, the function returns that the best feature to split on at the root node is feature 2 (\"Solitary\")\n",
    "\n",
    "\n",
    "## 5 - Building the tree\n",
    "\n",
    "In this section, we use the functions you implemented above to generate a decision tree by successively picking the best feature to split on until we reach the stopping criteria (maximum depth is 2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d519173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not graded\n",
    "tree = []\n",
    "\n",
    "def build_tree_recursive(X, y, node_indices, branch_name, max_depth, current_depth):\n",
    "    \"\"\"\n",
    "    Build a tree using the recursive algorithm that split the dataset into 2 subgroups at each node.\n",
    "    This function just prints the tree.\n",
    "    \n",
    "    Args:\n",
    "        X (ndarray):            Data matrix of shape(n_samples, n_features)\n",
    "        y (array like):         list or ndarray with n_samples containing the target variable\n",
    "        node_indices (ndarray): List containing the active indices. I.e, the samples being considered in this step.\n",
    "        branch_name (string):   Name of the branch. ['Root', 'Left', 'Right']\n",
    "        max_depth (int):        Max depth of the resulting tree. \n",
    "        current_depth (int):    Current depth. Parameter used during recursive call.\n",
    "   \n",
    "    \"\"\" \n",
    "\n",
    "    # Maximum depth reached - stop splitting\n",
    "    if current_depth == max_depth:\n",
    "        formatting = \" \"*current_depth + \"-\"*current_depth\n",
    "        print(formatting, \"%s leaf node with indices\" % branch_name, node_indices)\n",
    "        return\n",
    "   \n",
    "    # Otherwise, get best split and split the data\n",
    "    # Get the best feature and threshold at this node\n",
    "    best_feature = get_best_split(X, y, node_indices) \n",
    "    \n",
    "    formatting = \"-\"*current_depth\n",
    "    print(\"%s Depth %d, %s: Split on feature: %d\" % (formatting, current_depth, branch_name, best_feature))\n",
    "    \n",
    "    # Split the dataset at the best feature\n",
    "    left_indices, right_indices = split_dataset(X, node_indices, best_feature)\n",
    "    tree.append((left_indices, right_indices, best_feature))\n",
    "    \n",
    "    # continue splitting the left and the right child. Increment current depth\n",
    "    build_tree_recursive(X, y, left_indices, \"Left\", max_depth, current_depth+1)\n",
    "    build_tree_recursive(X, y, right_indices, \"Right\", max_depth, current_depth+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "be502937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Depth 0, Root: Split on feature: 2\n",
      "- Depth 1, Left: Split on feature: 0\n",
      "  -- Left leaf node with indices [0, 1, 4, 7]\n",
      "  -- Right leaf node with indices [5]\n",
      "- Depth 1, Right: Split on feature: 1\n",
      "  -- Left leaf node with indices [8]\n",
      "  -- Right leaf node with indices [2, 3, 6, 9]\n"
     ]
    }
   ],
   "source": [
    "build_tree_recursive(X_train, y_train, root_indices, \"Root\", max_depth=2, current_depth=0)\n",
    "#generate_tree_viz(root_indices, y_train, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb70521f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
